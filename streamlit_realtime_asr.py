# -*- coding: utf-8 -*-
"""streamlit_realtime_asr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ux98KL0g0g_d3D67KaerLCuEjIcyUD1q
"""

import streamlit as st
import numpy as np
from transformers import pipeline
import sounddevice as sd
import threading
import queue
import time

# 初始化Whisper模型
@st.cache_resource
def load_model():
    return pipeline("automatic-speech-recognition", model="openai/whisper-small")

# 音訊處理設定
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_DURATION = 3  # 每次處理3秒的音訊
CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_DURATION)

# 初始化音訊隊列
audio_queue = queue.Queue()
is_recording = False

def audio_callback(indata, frames, time, status):
    """音訊回調函數，接收麥克風輸入"""
    if is_recording:
        audio_queue.put(indata.copy())

def process_audio(asr_pipeline):
    """處理音訊並進行ASR"""
    while is_recording:
        if not audio_queue.empty():
            # 從隊列獲取音訊數據
            audio_data = audio_queue.get()

            # 確保音訊格式正確
            audio_data = audio_data.flatten()

            try:
                # 執行ASR
                result = asr_pipeline({"sampling_rate": SAMPLE_RATE, "raw": audio_data})
                if result["text"].strip():
                    st.session_state.transcription += result["text"] + " "
            except Exception as e:
                st.error(f"ASR處理錯誤: {str(e)}")
        time.sleep(0.1)

def main():
    st.title("即時語音辨識")

    # 載入模型
    asr_pipeline = load_model()

    # 初始化轉錄文本
    if "transcription" not in st.session_state:
        st.session_state.transcription = ""

    # 建立開始/停止按鈕
    global is_recording
    if st.button("開始錄音" if not is_recording else "停止錄音"):
        is_recording = not is_recording

        if is_recording:
            # 開始新的錄音session
            st.session_state.transcription = ""

            # 啟動音訊處理線程
            process_thread = threading.Thread(target=process_audio, args=(asr_pipeline,))
            process_thread.start()

            # 啟動音訊串流
            try:
                with sd.InputStream(
                    channels=CHANNELS,
                    samplerate=SAMPLE_RATE,
                    callback=audio_callback,
                    blocksize=CHUNK_SIZE
                ):
                    st.success("正在錄音...")
                    while is_recording:
                        time.sleep(0.1)
            except Exception as e:
                st.error(f"錄音錯誤: {str(e)}")
        else:
            st.warning("錄音已停止")

    # 顯示轉錄文本
    st.text_area("轉錄結果", value=st.session_state.transcription, height=200)

    # 清除按鈕
    if st.button("清除轉錄"):
        st.session_state.transcription = ""

if __name__ == "__main__":
    main()